---
title: "Pset 6"
author: "Aditya Khera"
date: "4/19/2022"
output: pdf_document
---

```{r setup}
knitr::opts_chunk$set(echo = TRUE)
# Income and Job Satisfaction: Homework 6 Problem 1
# Proportional odds logistic regression model
rm(list=ls())
# Key in data
Count <- c(2,2,0,0, 4,6,1,3, 13,22,15,13, 3,4,8,8)
Count
JobSat.levels <- c("VeryDis", "LittleDis", "ModSat", "VerySat")
JobSat <- rep(JobSat.levels, c(4,4,4,4))
JobSat <- factor(JobSat, levels=JobSat.levels, ordered=T)
rm(JobSat.levels)
JobSat  # Response variable -- ordinal with 4 levels
Income.levels <- c(" < 5", " 5-15", "15-25", " >25")
Income <- rep(Income.levels, 4)
Income <- factor(Income, levels=Income.levels)
rm(Income.levels)
Income
x <- rep(c(3,10,20,30), 4)
x
Data <- data.frame(Income, x, JobSat, Count);   Data;
rm(Income, x, JobSat, Count);  
table <- xtabs(Count ~ Income + JobSat, data=Data)
# This should match the data table given in the assignment
```

```{r problem 1a}
table
library(MASS)
fit <- polr(JobSat ~ x, data=Data, weights=Count, method = "logistic")
summary(fit)
```

According to the summary we derive that logit[P(Y<j)] = Bj0 - 0.056x
Where B10 = -2.4732, B20 = -0.7817, B30 = 2.2111

```{r problem 1b}
trial = data.frame("x" = c(3, 10, 20, 30, 35))
vals <- (predict(fit, newdata = trial, type= "probs"))
rownames(vals) <- c("<5000", "5000-15000", "15000-25000", ">25000", "35000")
vals
```

```{r problem 1c}
fit.null <- update(fit, ~ -x)
anova(fit, fit.null, test = "Chisq")
```
When running an anova test, we obtain an LRT statistic of 7.514 and a corresponding p-values of 0.0061. Such a low p-value leads us to reject the null hypothesis, we reject that B1 = 0. There must be some significance of income on a person's job satisfaction.


```{r problem 1d}
round(exp(1* -fit$coefficients), 2)
conf.beta <- confint(fit)
CI <- exp(1 * -conf.beta)
CI
```

The estimated odds of satisfaction with a persons job change by .95 for a 1000 dollar increase in income, holding the other variables. We are also 95% confident that the true odds ratio lies between <.906, .984>, for a change in income of $1000. The odds ratio stays the same no matter what response category is used, so it actually doesn't matter if we include the category/level of job satisfaction in our odds ratio.

```{r problem 1e}
xvals <- data.frame("x" = c(0:35))
seq <- c(0:35)
predplot <- predict(fit, newdata = xvals, type = "probs")
plot(seq, predplot[, 1], type="l", lwd=2, ylim=c(0,1), xlab="Income (in thousands)", ylab="Estimated probabilty", main="")
lines(seq,predplot[, 2], lty=2, lwd=2)
lines(seq,predplot[, 3], lty=3, lwd=3)
lines(seq,predplot[, 4], lty=4, lwd=4)
legend("topright", inset=.05, lwd=2, lty=1:4, legend = c("Very Dissatisfied", "A Little Satisfied", "Moderately Satisfied", "Very Satisfied"))
```

```{r problem 2a}
crabs <- read.csv("/Users/adityakhera/Desktop/Statistics/Categorical Data/Crabs.csv")
crab.fit <- glm(sat ~ width, data = crabs, family = poisson(link="log"))
summary(crab.fit)
```
log(pi) = -3.30 + 0.16*width,
pi(width) = exp(-3.30 + .16*width)

```{r problem 2b}
crab.fit.null <- update(crab.fit, ~. - width)
anova(crab.fit.null, crab.fit, test = "Chisq")
```
The LRT statistic reported form our anova test is 64.913 and the associated p-value is well under .0001. This means that we have very strong evidence of a correlation between width and satellite number, we reject the null hypothesis at this level.

```{r problem 2c}
#sat num = 5, 5 = exp(-3.3 + .16*width)
(log(5)+3.3)/.16
```
According to the model, we can estimate that a width of 31 (or 30.69) or more corresponds to a number of sats that is greater than five. 

```{r problem 2d}
exp(4*confint(crab.fit)[2,])
```
We can be 95% confident that the true ratio of means is between <1.65, 2.25> given a difference of 4-cm. This confidence interval would not change between different measurments, so long as the difference in widths remained the same.

```{r problem 2e}
#given the our solution to 2c, a width of 30 is a little under 5 satelleites, we can name it as approx 4.9, SE from the model is 0.02105.
4.9 +c(-1,1)*qnorm(.975)*0.02105
```
We can say the confidence interval around pi(30) is approximately <4.86 4.94>.

```{r problem 2f}
plot(jitter(crabs$width), crabs$sat)
xvals <- seq(21, 33.5, .5)
beta0.hat <- coef(crab.fit)["(Intercept)"]
beta1.hat <- coef(crab.fit)["width"]
mu.hat <- exp(beta0.hat + beta1.hat*xvals)
lines(xvals, mu.hat, lwd=2)
LP <- predict(crab.fit, data.frame(width=xvals), type="link", se.fit=T)
mu.hat <- exp(LP$fit)
CI.lo <- exp(LP$fit - qnorm(.975) * LP$se.fit)
CI.hi <- exp(LP$fit + qnorm(.975) * LP$se.fit)
lines(xvals, CI.lo, lty=2, lwd=2)
lines(xvals, CI.hi, lty=2, lwd=2)
```


```{r problem 3a}
crabs$color <-as.factor(crabs$color)
crab.color.fit <- glm(sat ~ width + color, data = crabs, family = poisson(link="log"))
summary(crab.color.fit)
```
log(pi) = -2.65004 +  0.15*width -0.20color2 -0.44color3 -0.45color4

```{r problem 3b}
crab.nocol <- update(crab.color.fit, ~. - color)
anova(crab.nocol, crab.color.fit, test = "Chisq")
```
Preforming an anova test, we obtain a LRT of 8.5338 and a corresponding p-value of .036, meaning we can reject the null hypothesis. There is likely a relationship between color and satellite number, according to the results of our chisq test. 

```{r problem 3c}
crab.mega <- glm(sat ~ width + color + width:color, data = crabs, family = poisson(link="log"))
summary(crab.mega)
anova(crab.color.fit, crab.mega, test = "Chisq")
```
log(pi) = 3.57144 -.81width -6.13color1 -8.52color2 -8.52color3 -10.54color4 + .22width:color1 + .3width:color3 + .38width:color4
Using an anova test, we obtain a LRT of 11.78 and a corresponding p-value of .008. With this value, we have reasonable evidence that the interaction between width and color plays a role in the number of satellites. 

```{r problem 3d}
trial <- data.frame(width = 30, color= c("1", "2", "3", "4"))
predict(crab.mega, newdata = trial, type = "response")
```

